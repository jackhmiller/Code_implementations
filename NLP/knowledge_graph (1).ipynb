{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6b4a4a7-2a2e-43bc-8234-428073d691d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0905c49a-45b2-475f-922e-6eab4c2bba17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67521c0b5ccd4f9a97bf9b8057d8cbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97107541-b7d6-457f-b1e0-c44d48843881",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636eb174-a7c3-4da6-93ac-498c6acfbd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names = os.listdir('./pdfs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab60d1b-3f6e-45de-975b-d8ddf9cb1792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdfs = [os.path.join(\"./pdfs/\", i) for i in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "808acaec-94b0-4920-801d-d5e05f21bc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for file in pdfs:\n",
    "with open(pdfs[0], 'rb') as pdf:\n",
    "    text = ''\n",
    "    reader = PyPDF2.PdfReader(pdf)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff4ec18d-083c-488c-b79b-6c03f88f9244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pages = 3525\n",
    "tbook_len = len(text)\n",
    "n_segments = tbook_len//num_pages\n",
    "\n",
    "# Tt seems that each disease is more or less on a single page, so rather than try and parse the information in the text using \n",
    "# the table of contents, I tried to extract each page with the idea that I could build NER per page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3cd0edf-6300-4f6b-8733-620c4783b222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text(text, num_segments):\n",
    "    chunk_size = len(text)//num_segments\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for i in range(num_segments):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "    chunks.append(text[start:])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5196cbdc-b8a5-4153-a2c9-7c2cadc36620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments = split_text(text, n_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fd08c-8a50-496e-974c-13f31ae227ba",
   "metadata": {},
   "source": [
    "## NER Triplet Extraction and building the graph\n",
    "Given the large size of the texbook, I tried to extract triplets per page (one disease) at a time, and then build a graph based on that page. The process would iterate over each page, building a graph per page (while not adding exisiting entities) and iteratively combining the graphs until all the pages had been iterated over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b283716d-f362-4295-b3a3-9f7d0520a6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip()\n",
    "        })\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d349c158-e95f-441a-8bba-8dfd7aa8b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "            \n",
    "    def get_entities(self, e):\n",
    "        return set([*[self.relations[i]['tail'] for i in range(len(self.relations))], *[self.relations[i]['head'] for i in range(len(self.relations))]])\n",
    "            \n",
    "    def merge_relations(self, r1):\n",
    "        r2 = [r for r in self.relations\n",
    "              if self.are_relations_equal(r1, r)][0]\n",
    "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
    "                        if span not in r2[\"meta\"][\"spans\"]]\n",
    "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "        else:\n",
    "            self.merge_relations(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07e29a36-d9ba-4a0f-a009-ce45ee1f69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_text_to_kb(text, span_length=128):\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "\n",
    "    num_tokens = len(inputs[\"input_ids\"][0])\n",
    "    \n",
    "    num_spans = math.ceil(num_tokens / span_length)\n",
    "    \n",
    "    overlap = math.ceil((num_spans * span_length - num_tokens) / \n",
    "                        max(num_spans - 1, 1))\n",
    "    spans_boundaries = []\n",
    "    start = 0\n",
    "    for i in range(num_spans):\n",
    "        spans_boundaries.append([start + span_length * i,\n",
    "                                 start + span_length * (i + 1)])\n",
    "        start -= overlap\n",
    "\n",
    "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]] for boundary in spans_boundaries]\n",
    "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]] for boundary in spans_boundaries]\n",
    "    inputs = {\"input_ids\": torch.stack(tensor_ids),\n",
    "              \"attention_mask\": torch.stack(tensor_masks)}\n",
    "\n",
    "    num_return_sequences = 3\n",
    "    gen_kwargs = {\"max_length\": 256,\n",
    "                \"length_penalty\": 0,\n",
    "                \"num_beams\": 3,\n",
    "                \"num_return_sequences\": num_return_sequences}\n",
    "    \n",
    "    generated_tokens = model.generate(**inputs,\n",
    "                                      **gen_kwargs,)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
    "                                           skip_special_tokens=False)\n",
    "\n",
    "    kb = KB()\n",
    "    i = 0\n",
    "    for sentence_pred in decoded_preds:\n",
    "        current_span_index = i // num_return_sequences\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for relation in relations:\n",
    "            relation[\"meta\"] = {\n",
    "                \"spans\": [spans_boundaries[current_span_index]]\n",
    "            }\n",
    "            kb.add_relation(relation)\n",
    "        i += 1\n",
    "\n",
    "    entities = kb.get_entities()\n",
    "    \n",
    "    return kb.relations, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727283f-f7f4-4e00-9931-e952e5ad3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING this will take a long time to run\n",
    "\n",
    "all_relations = []\n",
    "all_entities = []\n",
    "for segment in segments:\n",
    "    relations, entities = from_text_to_kb(segment)\n",
    "    all_relations.append(relations)\n",
    "    all_entities.append(entities)\n",
    "    \n",
    "final_relations = list(set(itertools.chain(*all_relations)))\n",
    "final_entities = list(set(itertools.chain(*all_entities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce8608-c421-429e-b73b-14368776d9d2",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df358600-7fcc-48a8-8193-2bc96b97885c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0b50aa1-f810-4b29-9e5d-267f9fbd54ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_network_html(relations, entities, filename=\"network.html\"):\n",
    "    net = Network(directed=True, width=\"auto\", height=\"700px\", bgcolor=\"#eeeeee\")\n",
    "    color_entity = \"#00FF00\"\n",
    "    for e in entities: #kb.entities:\n",
    "        net.add_node(e, shape=\"circle\", color=color_entity)\n",
    "\n",
    "    for r in relations:\n",
    "        net.add_edge(r[\"head\"], r[\"tail\"],\n",
    "                    title=r[\"type\"], label=r[\"type\"])\n",
    "\n",
    "    net.repulsion(\n",
    "        node_distance=200,\n",
    "        central_gravity=0.2,\n",
    "        spring_length=200,\n",
    "        spring_strength=0.05,\n",
    "        damping=0.09\n",
    "    )\n",
    "    net.set_edge_smooth('dynamic')\n",
    "    net.show(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86d7cdce-5112-42b8-8971-cf08caaf379f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"kg.html\"\n",
    "save_network_html(final_relations, final_entities, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8d72f-86b3-43e1-a9fd-4fdcb9dc0139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ball_tracking",
   "language": "python",
   "name": "ball_tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
